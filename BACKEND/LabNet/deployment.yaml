apiVersion: apps/v1
kind: Deployment
metadata:
  name: espectaculos-app
spec:
  replicas: 2
  selector:
    matchLabels:
      app: espectaculos
  template:
    metadata:
      labels:
        app: espectaculos
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8080"
        prometheus.io/path: "/metrics"
    spec:
      containers:
      - name: espectaculos
        image: 466060356317.dkr.ecr.us-east-1.amazonaws.com/espectaculos-web:latest
        ports:
        - containerPort: 8080
        # 1) Resource requests y limits (HPA necesita requests para calcular correctamente)
        resources:
          requests:
            cpu: "250m"
            memory: "512Mi"
          limits:
            cpu: "1000m"
            memory: "1Gi"
        # 2) Readiness probe (no recibir tr√°fico hasta estar listo)
        readinessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 10
          periodSeconds: 5
          timeoutSeconds: 2
          failureThreshold: 3
        # 3) Liveness probe (reiniciar si se queda colgado)
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 15
          timeoutSeconds: 3
          failureThreshold: 3
        env:
        - name: ASPNETCORE_URLS
          value: "http://+:8080"
        - name: CORS_ORIGINS
          value: "http://localhost:8080,http://mi-frontend-react-58b37209876tyg9.s3-website-us-east-1.amazonaws.com,http://localhost:5262"
        - name: Cors__AllowedOrigins
          value: "http://localhost:8080,http://mi-frontend-react-58b37209876tyg9.s3-website-us-east-1.amazonaws.com,http://localhost:5262"
        - name: ConnectionStrings__Default
          value: "Host=postgres-db.cb6u64euqqve.us-east-1.rds.amazonaws.com;Port=5432;Database=espectaculosdb;Username=postgres_user;Password=postgres_user"
        - name: DEFAULT_CONNECTION
          value: "Host=postgres-db.cb6u64euqqve.us-east-1.rds.amazonaws.com;Port=5432;Database=espectaculosdb;Username=postgres_user;Password=postgres_user"
        - name: REDIS_CONNECTION_STRING
          value: "redis-cluster.qatxfp.0001.use1.cache.amazonaws.com:6379"
        - name: AWS__Region
          value: "us-east-1"
        - name: AWS__Cognito__UserPoolId
          value: "us-east-1_TBr5rbzDq"
        - name: AWS__Cognito__ClientId
          value: "4s35v2gjsnc6l2rgc8bh9tsbuj"
        - name: AWS__Cognito__Region
          value: "us-east-1"
        - name: AWS_ACCESS_KEY_ID
          valueFrom:
            secretKeyRef:
              name: aws-creds
              key: aws_access_key_id
        - name: AWS_SECRET_ACCESS_KEY
          valueFrom:
            secretKeyRef:
              name: aws-creds
              key: aws_secret_access_key
        - name: AWS_SESSION_TOKEN
          valueFrom:
            secretKeyRef:
              name: aws-creds
              key: aws_session_token
        - name: REDIS__ENDPOINT
          value: "redis-cluster.qatxfp.0001.use1.cache.amazonaws.com"
        - name: OTEL_EXPORTER_OTLP_ENDPOINT
          value: "http://otel-collector:4318"
        - name: OTEL_METRICS_EXPORTER
          value: "otlp"
        - name: OTEL_TRACES_EXPORTER
          value: "otlp"
        - name: OTEL_LOGS_EXPORTER
          value: "otlp"
        - name: OTEL_RESOURCE_ATTRIBUTES
          value: "service.name=espectaculos,service.namespace=production"
        - name: OTEL_EXPORTER_OTLP_METRICS_ENDPOINT
          value: "http://otel-collector:4318/v1/metrics"
        - name: OTEL_EXPORTER_OTLP_TRACES_ENDPOINT
          value: "http://otel-collector:4318/v1/traces"
        - name: OTEL_EXPORTER_OTLP_PROTOCOL
          value: "http/protobuf"
        - name: OTEL_EXPORTER_OTLP_METRICS_PROTOCOL
          value: "http/protobuf"
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: espectaculos-hpa
  namespace: default
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: espectaculos-app
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 60


# SEQ
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: seq
spec:
  replicas: 1
  selector:
    matchLabels:
      app: seq
  template:
    metadata:
      labels:
        app: seq
    spec:
      securityContext:
        fsGroup: 1000
      containers:
        - name: seq
          image: datalust/seq:2024.3
          env:
            - name: ACCEPT_EULA
              value: "Y"
          ports:
            - containerPort: 80
          volumeMounts:
            - name: seq-storage
              mountPath: /data
      volumes:
        - name: seq-storage
          emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: seq
spec:
  type: LoadBalancer
  selector:
    app: seq
  ports:
    - port: 80
      targetPort: 80

# TEMPO
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: tempo-config
data:
  tempo.yaml: |
    server:
      http_listen_port: 3200

    distributor:
      receivers:
        otlp:
          protocols:
            http:
            grpc:

    storage:
      trace:
        backend: local
        local:
          path: /tmp/tempo/blocks
        wal:
          path: /tmp/tempo/wal
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: tempo
spec:
  replicas: 1
  selector:
    matchLabels:
      app: tempo
  template:
    metadata:
      labels:
        app: tempo
    spec:
      containers:
        - name: tempo
          image: grafana/tempo:2.5.0
          args: ["-config.file=/etc/tempo/tempo.yaml"]
          volumeMounts:
            - mountPath: /etc/tempo
              name: tempo-config
      volumes:
        - name: tempo-config
          configMap:
            name: tempo-config
---
apiVersion: v1
kind: Service
metadata:
  name: tempo
spec:
  selector:
    app: tempo
  ports:
    - name: http
      port: 3200
      targetPort: 3200
    - name: otlp-grpc
      port: 4317
    - name: otlp-http
      port: 4318

# OTEL COLLECTOR
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: otel-config
data:
  config.yaml: |
    receivers:
      otlp:
        protocols:
          http:
          grpc:

    processors:
      batch: {}

    exporters:
      prometheus:
        endpoint: "0.0.0.0:9464"
      otlp:
        endpoint: "tempo:4317"
        tls:
          insecure: true

    service:
      pipelines:
        metrics:
          receivers: [otlp]
          processors: [batch]
          exporters: [prometheus]

        traces:
          receivers: [otlp]
          processors: [batch]
          exporters: [otlp]
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: otel-collector
spec:
  replicas: 1
  selector:
    matchLabels:
      app: otel-collector
  template:
    metadata:
      labels:
        app: otel-collector
    spec:
      containers:
        - name: otel-collector
          image: otel/opentelemetry-collector-contrib:0.102.1
          args: ["--config=/etc/otel/config.yaml"]
          volumeMounts:
            - name: otel-config
              mountPath: /etc/otel
          ports:
            - containerPort: 4317
            - containerPort: 4318
            - containerPort: 9464
      volumes:
        - name: otel-config
          configMap:
            name: otel-config
---
apiVersion: v1
kind: Service
metadata:
  name: otel-collector
spec:
  selector:
    app: otel-collector
  ports:
    - name: otlp-grpc
      port: 4317
    - name: otlp-http
      port: 4318
    - name: metrics
      port: 9464

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-provisioning
  namespace: default
data:
  dashboards.yml: |
    apiVersion: 1
    providers:
      - name: espectaculos-dashboards
        orgId: 1
        folder: Observability
        type: file
        options:
          path: /var/lib/grafana/dashboards
          foldersFromFilesStructure: true

  datasources.yml: |
    apiVersion: 1
    datasources:
      - name: Prometheus
        uid: prometheus
        type: prometheus
        access: proxy
        url: http://prometheus:9090
        isDefault: true
        editable: true

      - name: Tempo
        uid: tempo
        type: tempo
        access: proxy
        url: http://tempo:3200
        editable: true
        jsonData:
          httpMethod: GET
          tracesToMetrics:
            datasourceUid: prometheus
          serviceMap:
            datasourceUid: prometheus
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-dashboards
  namespace: default
data:
  espectaculos-observability.json: |
    {
      "id": null,
      "title": "Espect√°culos - Dashboard T√©cnico (3.5 Observabilidad)",
      "description": "Dashboard t√©cnico con indicadores de latencia, errores, sincronizaciones pendientes y trazabilidad con CorrelationId",
      "timezone": "browser",
      "schemaVersion": 39,
      "version": 3,
      "refresh": "10s",
      "tags": ["espectaculos", "otel", "prometheus", "observabilidad", "tecnico"],
      "panels": [
        { 
          "type": "row", 
          "title": "üìä INDICADORES CLAVE (SLOs)", 
          "collapsed": false,
          "gridPos": {"h": 1, "w": 24, "x": 0, "y": 0} 
        },
        {
          "type": "stat",
          "title": "üéØ P95 Latencia (SLO: < 300ms)",
          "description": "Percentil 95 de latencia - El 95% de las solicitudes se completan en este tiempo o menos",
          "gridPos": {"h": 4, "w": 6, "x": 0, "y": 1},
          "targets": [
            {
              "refId": "A",
              "expr": "histogram_quantile(0.95, sum by (le) (rate(http_server_request_duration_seconds_bucket[5m])))",
              "legendFormat": "P95"
            }
          ],
          "options": {
            "graphMode": "area",
            "colorMode": "value",
            "justifyMode": "auto",
            "textMode": "value_and_name",
            "reduceOptions": {"calcs": ["lastNotNull"], "fields": "", "values": false}
          },
          "fieldConfig": {
            "defaults": {
              "unit": "ms",
              "min": 0,
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {"color": "green", "value": null},
                  {"color": "yellow", "value": 300},
                  {"color": "red", "value": 500}
                ]
              }
            },
            "overrides": []
          }
        },
        {
          "type": "stat",
          "title": "üéØ P99 Latencia (SLO: < 500ms)",
          "description": "Percentil 99 de latencia - El 99% de las solicitudes se completan en este tiempo o menos",
          "gridPos": {"h": 4, "w": 6, "x": 6, "y": 1},
          "targets": [
            {
              "refId": "A",
              "expr": "histogram_quantile(0.99, sum by (le) (rate(http_server_request_duration_seconds_bucket[5m]))) * 1000",
              "legendFormat": "P99"
            }
          ],
          "options": {
            "graphMode": "area",
            "colorMode": "value",
            "justifyMode": "auto",
            "textMode": "value_and_name",
            "reduceOptions": {"calcs": ["lastNotNull"], "fields": "", "values": false}
          },
          "fieldConfig": {
            "defaults": {
              "unit": "ms",
              "min": 0,
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {"color": "green", "value": null},
                  {"color": "yellow", "value": 500},
                  {"color": "red", "value": 1000}
                ]
              }
            },
            "overrides": []
          }
        },
        {
          "type": "stat",
          "title": "‚ö° Tiempo Medio de Respuesta",
          "description": "Tiempo promedio de respuesta de todas las solicitudes HTTP",
          "gridPos": {"h": 4, "w": 6, "x": 12, "y": 1},
          "targets": [
            {
              "refId": "A",
              "expr": "(sum(rate(http_server_request_duration_seconds_sum[5m])) / sum(rate(http_server_request_duration_seconds_count[5m]))) * 1000",
              "legendFormat": "Promedio"
            }
          ],
          "options": {
            "graphMode": "area",
            "colorMode": "value",
            "justifyMode": "auto",
            "textMode": "value_and_name",
            "reduceOptions": {"calcs": ["lastNotNull"], "fields": "", "values": false}
          },
          "fieldConfig": {
            "defaults": {
              "unit": "ms",
              "min": 0,
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {"color": "green", "value": null},
                  {"color": "yellow", "value": 200},
                  {"color": "red", "value": 400}
                ]
              }
            },
            "overrides": []
          }
        },
        {
          "type": "stat",
          "title": "‚ùå Tasa de Errores (SLO: < 1%)",
          "description": "Porcentaje de solicitudes con errores (5xx)",
          "gridPos": {"h": 4, "w": 6, "x": 18, "y": 1},
          "targets": [
            {
              "refId": "A",
              "expr": "100 * (sum(rate(http_server_request_duration_seconds_count{http_response_status_code=~\"5..\"}[5m])) / sum(rate(http_server_request_duration_seconds_count[5m])))",
              "legendFormat": "Tasa Error %"
            }
          ],
          "options": {
            "graphMode": "area",
            "colorMode": "value",
            "justifyMode": "auto",
            "textMode": "value_and_name",
            "reduceOptions": {"calcs": ["lastNotNull"], "fields": "", "values": false}
          },
          "fieldConfig": {
            "defaults": {
              "unit": "percent",
              "min": 0,
              "max": 100,
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {"color": "green", "value": null},
                  {"color": "yellow", "value": 0.5},
                  {"color": "red", "value": 1}
                ]
              }
            },
            "overrides": []
          }
        },

        { 
          "type": "row", 
          "title": "üìà LATENCIA DETALLADA", 
          "collapsed": false,
          "gridPos": {"h": 1, "w": 24, "x": 0, "y": 5} 
        },
        {
          "type": "timeseries",
          "title": "Latencia: P50, P95, P99 (√∫ltimos 5 minutos)",
          "description": "Percentiles de latencia a lo largo del tiempo",
          "gridPos": {"h": 8, "w": 24, "x": 0, "y": 6},
          "targets": [
            {
              "refId": "A",
              "expr": "histogram_quantile(0.50, sum by (le) (rate(http_server_request_duration_seconds_bucket[5m]))) * 1000",
              "legendFormat": "P50 (mediana)"
            },
            {
              "refId": "B",
              "expr": "histogram_quantile(0.95, sum by (le) (rate(http_server_request_duration_seconds_bucket[5m]))) * 1000",
              "legendFormat": "P95 (SLO: < 300ms)"
            },
            {
              "refId": "C",
              "expr": "histogram_quantile(0.99, sum by (le) (rate(http_server_request_duration_seconds_bucket[5m]))) * 1000",
              "legendFormat": "P99 (SLO: < 500ms)"
            }
          ],
          "options": {
            "legend": {"displayMode": "list", "placement": "bottom", "calcs": ["mean", "lastNotNull"]}, 
            "tooltip": {"mode": "multi"}
          },
          "fieldConfig": {
            "defaults": {
              "unit": "ms",
              "min": 0,
              "custom": {
                "drawStyle": "line",
                "lineInterpolation": "smooth",
                "lineWidth": 2,
                "fillOpacity": 10,
                "showPoints": "never"
              }
            },
            "overrides": [
              {
                "matcher": {"id": "byName", "options": "P95 (SLO: < 300ms)"},
                "properties": [{"id": "color", "value": {"fixedColor": "yellow", "mode": "fixed"}}]
              },
              {
                "matcher": {"id": "byName", "options": "P99 (SLO: < 500ms)"},
                "properties": [{"id": "color", "value": {"fixedColor": "red", "mode": "fixed"}}]
              }
            ]
          }
        },
        {
          "type": "timeseries",
          "title": "Latencia por Endpoint (P95)",
          "description": "P95 de latencia desglosado por ruta HTTP",
          "gridPos": {"h": 8, "w": 24, "x": 0, "y": 14},
          "targets": [
            {
              "refId": "A",
              "expr": "histogram_quantile(0.95, sum by (le, http_route) (rate(http_server_request_duration_seconds_bucket[5m]))) * 1000",
              "legendFormat": "{{http_route}}"
            }
          ],
          "options": {
            "legend": {"displayMode": "table", "placement": "right", "calcs": ["mean", "max", "lastNotNull"]}, 
            "tooltip": {"mode": "multi"}
          },
          "fieldConfig": {
            "defaults": {
              "unit": "ms",
              "min": 0,
              "custom": {
                "drawStyle": "line",
                "lineInterpolation": "smooth",
                "lineWidth": 1,
                "fillOpacity": 5
              }
            },
            "overrides": []
          }
        },

        { "type": "row", "title": "Tr√°fico", "gridPos": {"h": 1, "w": 24, "x": 0, "y": 9} },
        {
          "type": "timeseries",
          "title": "RPS total",
          "gridPos": {"h": 7, "w": 12, "x": 0, "y": 10},
          "targets": [
            { "refId": "A", "expr": "sum(rate(http_server_request_duration_seconds_count[1m]))", "legendFormat": "rps" }
          ],
          "fieldConfig": {"defaults": {"unit": "req/s", "min": 0}, "overrides": []}
        },
        {
          "type": "timeseries",
          "title": "RPS por c√≥digo",
          "gridPos": {"h": 7, "w": 12, "x": 12, "y": 10},
          "targets": [
            { "refId": "A", "expr": "sum by (http_response_status_code) (rate(http_server_request_duration_seconds_count[1m]))", "legendFormat": "{{http_response_status_code}}" }
          ],
          "fieldConfig": {"defaults": {"unit": "req/s", "min": 0}, "overrides": []}
        },

        { "type": "row", "title": "Errores", "gridPos": {"h": 1, "w": 24, "x": 0, "y": 17} },
        {
          "type": "timeseries",
          "title": "Error rate 5xx (%)",
          "gridPos": {"h": 7, "w": 24, "x": 0, "y": 18},
          "targets": [
            { "refId": "A", "expr": "100 * sum(rate(http_server_request_duration_seconds_count{http_response_status_code=~\"5..\"}[5m])) / sum(rate(http_server_request_duration_seconds_count[5m]))", "legendFormat": "5xx %" }
          ],
          "fieldConfig": {"defaults": {"unit": "percentunit", "min": 0, "max": 100}, "overrides": []}
        },

        { "type": "row", "title": "Concurrencia", "gridPos": {"h": 1, "w": 24, "x": 0, "y": 25} },
        {
          "type": "gauge",
          "title": "Requests concurrentes",
          "gridPos": {"h": 7, "w": 12, "x": 0, "y": 26},
          "targets": [ { "refId": "A", "expr": "sum(http_server_active_requests)" } ],
          "options": {"reduceOptions": {"calcs": ["lastNotNull"], "fields": "", "values": false}, "showThresholdLabels": false, "showThresholdMarkers": true},
          "fieldConfig": {"defaults": {"unit": "none", "min": 0}, "overrides": []}
        },

        { "type": "row", "title": "Sincronizaciones", "gridPos": {"h": 1, "w": 24, "x": 0, "y": 33} },
        {
          "type": "gauge",
          "title": "Backlog de sincronizaciones pendientes",
          "gridPos": {"h": 7, "w": 12, "x": 0, "y": 34},
          "targets": [ { "refId": "A", "expr": "app_sincronizaciones_backlog" } ],
          "options": {"reduceOptions": {"calcs": ["lastNotNull"], "fields": "", "values": false}, "showThresholdLabels": false, "showThresholdMarkers": true},
          "fieldConfig": {
            "defaults": {
              "unit": "none",
              "min": 0,
              "thresholds": {"mode": "absolute", "steps": [ {"color": "green", "value": null}, {"color": "yellow", "value": 10}, {"color": "red", "value": 50} ]} 
            },
            "overrides": []
          }
        }
      ]
    }

---
# Prometheus rules
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: default
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s

    scrape_configs:
      # Scrapear m√©tricas del OTEL Collector
      - job_name: 'otel-collector'
        static_configs:
          - targets: ['otel-collector:9464']
      
      # Scrapear m√©tricas directamente de los pods de la aplicaci√≥n
      - job_name: 'espectaculos-app'
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_pod_ip, __meta_kubernetes_pod_annotation_prometheus_io_port]
            action: replace
            target_label: __address__
            regex: (.+);(.+)
            replacement: $1:$2
          - source_labels: [__meta_kubernetes_namespace]
            target_label: kubernetes_namespace
          - source_labels: [__meta_kubernetes_pod_name]
            target_label: kubernetes_pod_name
          - source_labels: [__meta_kubernetes_pod_label_app]
            target_label: app
      
      # Scrapear m√©tricas de los nodos de Kubernetes
      - job_name: 'kubernetes-nodes'
        kubernetes_sd_configs:
          - role: node
        relabel_configs:
          - action: labelmap
            regex: __meta_kubernetes_node_label_(.+)

    rule_files:
      - /etc/prometheus/rules/*.yml
---
# Grafana Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: grafana
  namespace: default
spec:
  replicas: 1
  selector:
    matchLabels:
      app: grafana
  template:
    metadata:
      labels:
        app: grafana
    spec:
      securityContext:
        fsGroup: 472
      containers:
        - name: grafana
          image: grafana/grafana:11.2.0
          env:
            - name: GF_SECURITY_ADMIN_PASSWORD
              value: "admin"
          ports:
            - containerPort: 3000
          volumeMounts:
            - name: grafana-provisioning
              mountPath: /etc/grafana/provisioning
            - name: grafana-dashboards
              mountPath: /var/lib/grafana/dashboards
      volumes:
        - name: grafana-provisioning
          configMap:
            name: grafana-provisioning
            items:
              - key: dashboards.yml
                path: dashboards/dashboards.yml
              - key: datasources.yml
                path: datasources/datasources.yml
        - name: grafana-dashboards
          configMap:
            name: grafana-dashboards
            items:
              - key: espectaculos-observability.json
                path: espectaculos-observability.json

---
apiVersion: v1
kind: Service
metadata:
  name: grafana
  namespace: default
spec:
  type: LoadBalancer
  selector:
    app: grafana
  ports:
    - port: 3000
      targetPort: 3000

---
# Prometheus Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus
  namespace: default
spec:
  replicas: 1
  selector:
    matchLabels:
      app: prometheus
  template:
    metadata:
      labels:
        app: prometheus
    spec:
      containers:
        - name: prometheus
          image: prom/prometheus:v2.54.1
          args:
            - "--config.file=/etc/prometheus/prometheus.yml"
            - "--storage.tsdb.path=/prometheus"
          ports:
            - containerPort: 9090
          volumeMounts:
            - name: prometheus-config
              mountPath: /etc/prometheus/prometheus.yml
              subPath: prometheus.yml
      volumes:
        - name: prometheus-config
          configMap:
            name: prometheus-config

---
apiVersion: v1
kind: Service
metadata:
  name: prometheus
  namespace: default
spec:
  type: ClusterIP
  selector:
    app: prometheus
  ports:
    - port: 9090
      targetPort: 9090
---
# Rabbit MQ
apiVersion: apps/v1
kind: Deployment
metadata:
  name: rabbitmq
  labels:
    app: rabbitmq
spec:
  replicas: 1
  selector:
    matchLabels:
      app: rabbitmq
  template:
    metadata:
      labels:
        app: rabbitmq
    spec:
      containers:
        - name: rabbitmq
          image: rabbitmq:management
          ports:
            - containerPort: 5672   # AMQP
            - containerPort: 15672  # Management UI
          env:
            - name: RABBITMQ_DEFAULT_USER
              value: admin
            - name: RABBITMQ_DEFAULT_PASS
              value: admin
---
apiVersion: v1
kind: Service
metadata:
  name: rabbitmq
spec:
  selector:
    app: rabbitmq
  ports:
    - name: amqp
      port: 5672
      targetPort: 5672
    - name: management
      port: 15672
      targetPort: 15672
  type: ClusterIP

---
# K6
apiVersion: v1
kind: ConfigMap
metadata:
  name: k6-scripts
  namespace: default
data:
  # 01-baseline.js - AGRESIVO: 50 VUs concurrentes
  01-baseline.js: |
    import http from 'k6/http';
    import { check, sleep } from 'k6';
    
    const BASE_URL = __ENV.BASE_URL || 'http://espectaculos-app:8080';
    
    export const options = {
        stages: [
            { duration: '1m', target: 50 },   // Ramp-up a 50 VUs
            { duration: '5m', target: 50 },   // Mantener 50 VUs
            { duration: '30s', target: 0 },   // Ramp-down
        ],
        thresholds: {
            'http_req_duration': ['p(95)<500', 'p(99)<1000'],
            'http_req_failed': ['rate<0.01'],
        },
    };
    
    export default function () {
        const headers = { 'Content-Type': 'application/json' };
        
        // Sin sleep entre requests - m√°xima presi√≥n
        http.batch([
            ['GET', `${BASE_URL}/health`, null, { headers }],
            ['GET', `${BASE_URL}/api/espacios`, null, { headers }],
            ['GET', `${BASE_URL}/api/usuarios`, null, { headers }],
            ['GET', `${BASE_URL}/api/beneficios`, null, { headers }],
        ]);
        
        check(http.get(`${BASE_URL}/api/credenciales`, { headers }), {
            'status is 200': (r) => r.status === 200
        });
        
        // Sleep muy corto - solo 100-300ms
        sleep(Math.random() * 0.2 + 0.1);
    }

  # 02-peak-load.js - BRUTAL: 500 VUs
  02-peak-load.js: |
    import http from 'k6/http';
    import { check, sleep } from 'k6';
    
    const BASE_URL = __ENV.BASE_URL || 'http://espectaculos-app:8080';
    
    export const options = {
        stages: [
            { duration: '2m', target: 200 },   // Calentamiento
            { duration: '3m', target: 500 },   // Pico masivo
            { duration: '5m', target: 500 },   // Mantener presi√≥n
            { duration: '2m', target: 0 },     // Cooldown
        ],
        thresholds: {
            'http_req_duration': ['p(95)<1000', 'p(99)<2000'],
            'http_req_failed': ['rate<0.05'],  // Permitir 5% errores
        },
    };
    
    export default function () {
        const headers = { 'Content-Type': 'application/json' };
        const endpoints = [
            `${BASE_URL}/health`,
            `${BASE_URL}/api/espacios`,
            `${BASE_URL}/api/usuarios`,
            `${BASE_URL}/api/beneficios`,
            `${BASE_URL}/api/credenciales`,
            `${BASE_URL}/api/roles`,
            `${BASE_URL}/api/dispositivos`,
        ];
        
        // Hacer 3 requests en paralelo
        const responses = http.batch([
            ['GET', endpoints[Math.floor(Math.random() * endpoints.length)]],
            ['GET', endpoints[Math.floor(Math.random() * endpoints.length)]],
            ['GET', endpoints[Math.floor(Math.random() * endpoints.length)]],
        ]);
        
        check(responses[0], {
            'status is 200 or 500': (r) => r.status === 200 || r.status >= 500,
        });
        
        // Sleep m√≠nimo
        sleep(0.05);  // 50ms
    }

  # 03-stress-test.js - INSANO: 1000 VUs
  03-stress-test.js: |
    import http from 'k6/http';
    import { check, sleep } from 'k6';
    
    const BASE_URL = __ENV.BASE_URL || 'http://espectaculos-app:8080';
    
    export const options = {
        stages: [
            { duration: '2m', target: 100 },    // Inicio suave
            { duration: '3m', target: 500 },    // Aceleraci√≥n
            { duration: '5m', target: 1000 },   // M√ÅXIMA PRESI√ìN
            { duration: '5m', target: 1000 },   // Mantener estr√©s
            { duration: '2m', target: 0 },      // Cooldown
        ],
        thresholds: {
            'http_req_failed': ['rate<0.10'],  // Permitir 10% errores bajo estr√©s
        },
    };
    
    export default function () {
        const headers = { 'Content-Type': 'application/json' };
        
        // Bombardeo de requests
        const endpoints = [
            `${BASE_URL}/api/espacios`,
            `${BASE_URL}/api/usuarios`,
            `${BASE_URL}/api/beneficios`,
        ];
        
        // 5 requests en paralelo por VU
        http.batch([
            ['GET', endpoints[0]],
            ['GET', endpoints[1]],
            ['GET', endpoints[2]],
            ['GET', endpoints[0]],
            ['GET', endpoints[1]],
        ]);
        
        // Sin sleep - presi√≥n continua
    }

  # 04-soak-test.js - RESISTENCIA: 200 VUs por 30 minutos
  04-soak-test.js: |
    import http from 'k6/http';
    import { check, sleep } from 'k6';
    
    const BASE_URL = __ENV.BASE_URL || 'http://espectaculos-app:8080';
    
    export const options = {
        stages: [
            { duration: '2m', target: 200 },    // Ramp-up
            { duration: '30m', target: 200 },   // Mantener 30 minutos
            { duration: '2m', target: 0 },      // Ramp-down
        ],
        thresholds: {
            'http_req_duration': ['p(95)<500', 'p(99)<1000'],
            'http_req_failed': ['rate<0.01'],
        },
    };
    
    export default function () {
        const headers = { 'Content-Type': 'application/json' };
        
        // Mezcla de endpoints para simular uso real
        const actions = [
            () => http.get(`${BASE_URL}/api/espacios`, { headers }),
            () => http.get(`${BASE_URL}/api/usuarios`, { headers }),
            () => http.batch([
                ['GET', `${BASE_URL}/api/beneficios`],
                ['GET', `${BASE_URL}/api/credenciales`],
            ]),
        ];
        
        const randomAction = actions[Math.floor(Math.random() * actions.length)];
        randomAction();
        
        sleep(Math.random() * 0.3 + 0.1);  // 100-400ms
    }

  # 05-spike-test.js - SPIKES EXTREMOS: 0‚Üí1000 en 10 segundos
  05-spike-test.js: |
    import http from 'k6/http';
    import { check, sleep } from 'k6';
    
    const BASE_URL = __ENV.BASE_URL || 'http://espectaculos-app:8080';
    
    export const options = {
        stages: [
            { duration: '10s', target: 50 },     // Base
            { duration: '10s', target: 1000 },   // SPIKE BRUTAL
            { duration: '1m', target: 1000 },    // Mantener spike
            { duration: '10s', target: 50 },     // Bajar
            { duration: '30s', target: 50 },     // Recuperaci√≥n
            { duration: '10s', target: 1500 },   // SEGUNDO SPIKE M√ÅS GRANDE
            { duration: '1m', target: 1500 },    // Mantener
            { duration: '10s', target: 50 },     // Bajar
            { duration: '30s', target: 50 },     // Recuperaci√≥n
            { duration: '10s', target: 2000 },   // SPIKE FINAL M√ÅXIMO
            { duration: '1m', target: 2000 },    // Mantener
            { duration: '30s', target: 0 },      // Fin
        ],
        thresholds: {
            'http_req_duration': ['p(95)<2000', 'p(99)<5000'],
            'http_req_failed': ['rate<0.15'],  // Permitir 15% errores en spikes
        },
    };
    
    export default function () {
        const headers = { 'Content-Type': 'application/json' };
        
        // Bombardeo de requests sin batch para m√°xima concurrencia
        http.get(`${BASE_URL}/api/espacios`, { headers });
        http.get(`${BASE_URL}/api/usuarios`, { headers });
        
        // Sin sleep - presi√≥n m√°xima
    }

  # 06-breakpoint-test.js - ENCONTRAR L√çMITE: Incremento progresivo hasta romper
  06-breakpoint-test.js: |
    import http from 'k6/http';
    import { check, sleep } from 'k6';
    
    const BASE_URL = __ENV.BASE_URL || 'http://espectaculos-app:8080';
    
    export const options = {
        stages: [
            { duration: '2m', target: 100 },
            { duration: '2m', target: 200 },
            { duration: '2m', target: 400 },
            { duration: '2m', target: 600 },
            { duration: '2m', target: 800 },
            { duration: '2m', target: 1000 },
            { duration: '2m', target: 1200 },
            { duration: '2m', target: 1500 },
            { duration: '2m', target: 2000 },
            { duration: '2m', target: 2500 },
            { duration: '2m', target: 3000 },   // Aqu√≠ probablemente rompa
            { duration: '1m', target: 0 },
        ],
        thresholds: {
            'http_req_failed': ['rate<0.25'],  // Permitir 25% errores al final
        },
    };
    
    export default function () {
        const headers = { 'Content-Type': 'application/json' };
        
        // Request simple para medir capacidad pura
        const res = http.get(`${BASE_URL}/api/espacios`, { headers });
        
        check(res, {
            'not timeout': (r) => r.timings.duration < 30000,
        });
        
        // Sin sleep - m√°xima presi√≥n
    }

  # 07-constant-arrival-rate.js - TASA CONSTANTE: 5000 RPS garantizados
  07-constant-arrival-rate.js: |
    import http from 'k6/http';
    import { check } from 'k6';
    
    const BASE_URL = __ENV.BASE_URL || 'http://espectaculos-app:8080';
    
    export const options = {
        scenarios: {
            constant_request_rate: {
                executor: 'constant-arrival-rate',
                rate: 5000,           // 5000 requests por segundo
                timeUnit: '1s',
                duration: '5m',
                preAllocatedVUs: 500,
                maxVUs: 2000,
            },
        },
        thresholds: {
            'http_req_duration': ['p(95)<1000'],
            'http_req_failed': ['rate<0.10'],
        },
    };
    
    export default function () {
        const headers = { 'Content-Type': 'application/json' };
        
        const res = http.get(`${BASE_URL}/api/espacios`, { headers });
        
        check(res, {
            'status is 200': (r) => r.status === 200,
            'response time OK': (r) => r.timings.duration < 1000,
        });
    }

  # server.py
  server.py: |
    from http.server import HTTPServer, BaseHTTPRequestHandler
    import subprocess
    import json
    import os
    import select
    import time
    
    class K6Handler(BaseHTTPRequestHandler):
        def log_message(self, format, *args):
            print(f"[{self.log_date_time_string()}] {format % args}")
        
        def do_GET(self):
            if self.path == '/health':
                self.send_response(200)
                self.send_header('Content-type', 'application/json')
                self.end_headers()
                self.wfile.write(json.dumps({"status": "healthy", "service": "k6-runner"}).encode())
            
            elif self.path == '/scenarios':
                self.send_response(200)
                self.send_header('Content-type', 'application/json')
                self.end_headers()
                scenarios = [f for f in os.listdir('/scripts') if f.endswith('.js')]
                self.wfile.write(json.dumps({"scenarios": sorted(scenarios)}).encode())
            
            else:
                self.send_response(404)
                self.send_header('Content-type', 'application/json')
                self.end_headers()
                self.wfile.write(json.dumps({"error": "Not found. Try /health or /scenarios"}).encode())
        
        def do_POST(self):
            if self.path.startswith('/run/'):
                scenario = self.path.split('/')[-1]
                
                if not scenario.endswith('.js'):
                    scenario += '.js'
                
                script_path = f'/scripts/{scenario}'
                
                if not os.path.exists(script_path):
                    self.send_response(404)
                    self.send_header('Content-type', 'application/json')
                    self.end_headers()
                    self.wfile.write(json.dumps({
                        "error": f"Scenario {scenario} not found",
                        "available": [f for f in os.listdir('/scripts') if f.endswith('.js')]
                    }).encode())
                    return
                
                try:
                    self.send_response(200)
                    self.send_header('Content-type', 'text/event-stream')
                    self.send_header('Cache-Control', 'no-cache')
                    self.send_header('Connection', 'keep-alive')
                    self.send_header('X-Accel-Buffering', 'no')
                    self.end_headers()
                    
                    def send_event(data):
                        try:
                            self.wfile.write(f"data: {json.dumps(data)}\n\n".encode())
                            self.wfile.flush()
                        except:
                            pass
                    
                    send_event({'status': 'started', 'scenario': scenario})
                    
                    print(f"Running k6 test: {scenario}")
                    
                    process = subprocess.Popen(
                        ['k6', 'run', script_path],
                        cwd='/scripts',
                        stdout=subprocess.PIPE,
                        stderr=subprocess.STDOUT,
                        text=False,
                        bufsize=0
                    )
                    
                    last_heartbeat = time.time()
                    output_buffer = b''
                    
                    while True:
                        # Usar select para timeout de 30 segundos
                        ready, _, _ = select.select([process.stdout], [], [], 30)
                        
                        if ready:
                            # Hay datos disponibles
                            chunk = process.stdout.read(1024)
                            if not chunk:
                                break
                            
                            output_buffer += chunk
                            
                            # Procesar l√≠neas completas
                            while b'\n' in output_buffer:
                                line, output_buffer = output_buffer.split(b'\n', 1)
                                try:
                                    line_str = line.decode('utf-8', errors='replace').strip()
                                    if line_str:
                                        send_event({'output': line_str})
                                except:
                                    pass
                            
                            last_heartbeat = time.time()
                        else:
                            # Timeout - enviar heartbeat
                            current_time = time.time()
                            if current_time - last_heartbeat > 10:
                                send_event({'heartbeat': int(current_time)})
                                last_heartbeat = current_time
                        
                        # Verificar si el proceso termin√≥
                        if process.poll() is not None:
                            break
                    
                    # Procesar cualquier output restante
                    if output_buffer:
                        try:
                            line_str = output_buffer.decode('utf-8', errors='replace').strip()
                            if line_str:
                                send_event({'output': line_str})
                        except:
                            pass
                    
                    process.wait()
                    
                    result = {
                        'status': 'completed',
                        'scenario': scenario,
                        'exit_code': process.returncode,
                        'success': process.returncode == 0
                    }
                    
                    send_event(result)
                    
                    print(f"Test completed: {scenario} (exit code: {process.returncode})")
                
                except Exception as e:
                    print(f"Error running test: {str(e)}")
                    try:
                        error_msg = {'status': 'error', 'error': str(e)}
                        self.wfile.write(f"data: {json.dumps(error_msg)}\n\n".encode())
                        self.wfile.flush()
                    except:
                        pass
            
            else:
                self.send_response(404)
                self.send_header('Content-type', 'application/json')
                self.end_headers()
                self.wfile.write(json.dumps({"error": "Use POST /run/{scenario}"}).encode())
    
    if __name__ == '__main__':
        server = HTTPServer(('0.0.0.0', 8080), K6Handler)
        print('K6 Runner API listening on port 8080')
        print('Endpoints:')
        print('  GET  /health - Health check')
        print('  GET  /scenarios - List available scenarios')
        print('  POST /run/{scenario} - Run test (Server-Sent Events with heartbeat)')
        server.serve_forever()
---
# Deployment: k6 REST API
apiVersion: apps/v1
kind: Deployment
metadata:
  name: k6-runner
  namespace: default
  labels:
    app: k6-runner
spec:
  replicas: 1
  selector:
    matchLabels:
      app: k6-runner
  template:
    metadata:
      labels:
        app: k6-runner
    spec:
      securityContext:
        runAsNonRoot: false
        runAsUser: 0
      containers:
        - name: k6
          image: grafana/k6:latest
          command: ["/bin/sh"]
          args:
            - -c
            - |
              echo "Installing dependencies..."
              apk add --no-cache python3 curl
              
              echo "Starting k6 API server..."
              python3 /config/server.py
          ports:
            - containerPort: 8080
              name: http
          env:
            - name: BASE_URL
              value: "http://backend-service:80"
          volumeMounts:
            - name: k6-scripts
              mountPath: /scripts
            - name: k6-server
              mountPath: /config
          resources:
            requests:
              memory: "256Mi"
              cpu: "500m"
            limits:
              memory: "2Gi"
              cpu: "2000m"
          readinessProbe:
            httpGet:
              path: /health
              port: 8080
            initialDelaySeconds: 10
            periodSeconds: 5
          livenessProbe:
            httpGet:
              path: /health
              port: 8080
            initialDelaySeconds: 15
            periodSeconds: 10
      volumes:
        - name: k6-scripts
          configMap:
            name: k6-scripts
            items:
              - key: 01-baseline.js
                path: 01-baseline.js
              - key: 02-peak-load.js
                path: 02-peak-load.js
              - key: 03-stress-test.js
                path: 03-stress-test.js
              - key: 04-soak-test.js
                path: 04-soak-test.js
              - key: 05-spike-test.js
                path: 05-spike-test.js
        - name: k6-server
          configMap:
            name: k6-scripts
            items:
              - key: server.py
                path: server.py

---
# Service: LoadBalancer con timeout extendido
apiVersion: v1
kind: Service
metadata:
  name: k6-runner
  namespace: default
  labels:
    app: k6-runner
  annotations:
    # Timeout del ELB: 30 minutos (1800 segundos)
    service.beta.kubernetes.io/aws-load-balancer-connection-idle-timeout: "1800"
    # Habilitar keep-alive
    service.beta.kubernetes.io/aws-load-balancer-connection-draining-enabled: "true"
    service.beta.kubernetes.io/aws-load-balancer-connection-draining-timeout: "60"
spec:
  type: LoadBalancer
  selector:
    app: k6-runner
  ports:
    - name: http
      port: 80
      targetPort: 8080
      protocol: TCP

---
# CronJob: Baseline diario
apiVersion: batch/v1
kind: CronJob
metadata:
  name: k6-baseline-daily
  namespace: default
spec:
  schedule: "0 2 * * *"
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 3
  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure
          containers:
            - name: k6
              image: grafana/k6:latest
              command: ["k6"]
              args:
                - "run"
                - "/scripts/01-baseline.js"
              env:
                - name: BASE_URL
                  value: "http://backend-service:80"
              volumeMounts:
                - name: k6-scripts
                  mountPath: /scripts
              resources:
                requests:
                  memory: "256Mi"
                  cpu: "500m"
                limits:
                  memory: "1Gi"
                  cpu: "1000m"
          volumes:
            - name: k6-scripts
              configMap:
                name: k6-scripts
                items:
                  - key: 01-baseline.js
                    path: 01-baseline.js